{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a33b75-f67a-4b1d-927c-e097ac6646d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pywt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from scipy import stats\n",
    "from scipy.ndimage import laplace\n",
    "\n",
    "# Constants\n",
    "NOISE_LEVEL = 0.9  # Dose reduction level\n",
    "MAX_PHOTON_COUNT = 5e3\n",
    "OUTPUT_DIR = 'processed_images'\n",
    "CHEST_SAMPLES_DIR = 'chest_samples'\n",
    "FONT_PATH = '/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf'\n",
    "FONT_SIZE = 18\n",
    "IMG_SIZE = (512, 512)  # Define standard image size to match model's expected input\n",
    "\n",
    "\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def compute_image_quality_metrics(original, processed, noisy=None):\n",
    "    \"\"\"\n",
    "    Compute comprehensive image quality metrics.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Basic metrics\n",
    "    metrics['psnr'] = psnr(original, processed, data_range=1.0)\n",
    "    metrics['ssim'] = ssim(original, processed, data_range=1.0)\n",
    "    \n",
    "    # Edge preservation ratio\n",
    "    def compute_epr(img1, img2):\n",
    "        # Using numpy's gradient for edge detection instead of Laplace\n",
    "        grad1_x, grad1_y = np.gradient(img1)\n",
    "        grad2_x, grad2_y = np.gradient(img2)\n",
    "        \n",
    "        numerator = np.sum(grad1_x * grad2_x + grad1_y * grad2_y)\n",
    "        denominator = np.sqrt(np.sum(grad1_x**2 + grad1_y**2) * np.sum(grad2_x**2 + grad2_y**2))\n",
    "        \n",
    "        return numerator / denominator if denominator != 0 else 0.0\n",
    "    \n",
    "    metrics['epr'] = compute_epr(original, processed)\n",
    "    \n",
    "    # Noise reduction ratio if noisy image is provided\n",
    "    if noisy is not None:\n",
    "        noise_before = np.mean((original - noisy)**2)\n",
    "        noise_after = np.mean((original - processed)**2)\n",
    "        metrics['noise_reduction_ratio'] = noise_before / noise_after if noise_after != 0 else float('inf')\n",
    "    \n",
    "    # Calculate noise power spectrum\n",
    "    def compute_nps(img):\n",
    "        return np.abs(np.fft.fft2(img))**2\n",
    "        \n",
    "    nps_original = compute_nps(original)\n",
    "    nps_processed = compute_nps(processed)\n",
    "    metrics['nps_correlation'] = stats.pearsonr(nps_original.flatten(), nps_processed.flatten())[0]\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def add_noise(clean_img, dose_reduction=0.9, max_photon_count=5e3):\n",
    "    \"\"\"\n",
    "    Add Poisson noise to simulate X-ray noise.\n",
    "    \n",
    "    Parameters:\n",
    "    clean_img (ndarray): Input clean image\n",
    "    dose_reduction (float): Factor by which to reduce dose (0-1)\n",
    "    max_photon_count (float): Maximum number of photons\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: Noisy image\n",
    "    \"\"\"\n",
    "    # Scale image to photon counts\n",
    "    scaling_factor = 1.0 - dose_reduction\n",
    "    scaled_photon_counts = clean_img * max_photon_count * scaling_factor\n",
    "    \n",
    "    # Add Poisson noise\n",
    "    noisy_photon_counts = np.random.poisson(scaled_photon_counts)\n",
    "    \n",
    "    # Convert back to image scale\n",
    "    noisy_img = noisy_photon_counts / (max_photon_count * scaling_factor)\n",
    "    return np.clip(noisy_img, 0, 1)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "\n",
    "def print_quality_analysis(metrics):\n",
    "    \"\"\"Print detailed analysis of image quality metrics\"\"\"\n",
    "    print(\"\\nDetailed Image Quality Analysis:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"PSNR: {metrics['psnr']:.2f} dB\")\n",
    "    print(f\"SSIM: {metrics['ssim']:.4f}\")\n",
    "    print(f\"Edge Preservation Ratio: {metrics['epr']:.4f}\")\n",
    "    if 'noise_reduction_ratio' in metrics:\n",
    "        print(f\"Noise Reduction Ratio: {metrics['noise_reduction_ratio']:.2f}x\")\n",
    "    print(f\"NPS Correlation: {metrics['nps_correlation']:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def main():\n",
    "\n",
    "\n",
    "    # Process all images\n",
    "    print(f\"Processing images in {CHEST_SAMPLES_DIR}...\")\n",
    "    image_files = [f for f in os.listdir(CHEST_SAMPLES_DIR) \n",
    "                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    for image_file in tqdm(image_files):\n",
    "        image_path = os.path.join(CHEST_SAMPLES_DIR, image_file)\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        original_img = Image.open(image_path).convert('L')\n",
    "        original_img = original_img.resize(IMG_SIZE, Image.LANCZOS)\n",
    "        original_img = np.array(original_img, dtype=np.float32) / 255.0\n",
    "\n",
    "        # Add X-ray noise\n",
    "        noisy_img = add_noise(\n",
    "            original_img, \n",
    "            dose_reduction=NOISE_LEVEL, \n",
    "            max_photon_count=MAX_PHOTON_COUNT\n",
    "        )\n",
    "\n",
    "        # Compute features\n",
    "        fft_feat = compute_fft_features(noisy_img)\n",
    "        wavelet_feat_1 = compute_wavelet_features(noisy_img, WAVELET_TYPE_1, DECOMPOSITION_LEVEL)\n",
    "        wavelet_feat_2 = compute_wavelet_features(noisy_img, WAVELET_TYPE_2, DECOMPOSITION_LEVEL)\n",
    "        wavelet_feat_3 = compute_wavelet_features(noisy_img, WAVELET_TYPE_3, DECOMPOSITION_LEVEL)\n",
    "        wavelet_feat_4 = compute_wavelet_features(noisy_img, WAVELET_TYPE_4, DECOMPOSITION_LEVEL)\n",
    "\n",
    "        # Predict denoised image\n",
    "        predicted_img = model.predict([\n",
    "            noisy_img[tf.newaxis, ..., tf.newaxis],\n",
    "            fft_feat[tf.newaxis, ..., tf.newaxis],\n",
    "            wavelet_feat_1[tf.newaxis, ..., tf.newaxis],\n",
    "            wavelet_feat_2[tf.newaxis, ..., tf.newaxis],\n",
    "            wavelet_feat_3[tf.newaxis, ..., tf.newaxis],\n",
    "            wavelet_feat_4[tf.newaxis, ..., tf.newaxis]\n",
    "        ])[0, ..., 0]\n",
    "\n",
    "        # Compute quality metrics\n",
    "        metrics = compute_image_quality_metrics(\n",
    "            original=original_img,\n",
    "            processed=predicted_img,\n",
    "            noisy=noisy_img\n",
    "        )\n",
    "        \n",
    "        # Print analysis\n",
    "        print(f\"\\nAnalysis for {image_file}:\")\n",
    "        print_quality_analysis(metrics)\n",
    "\n",
    "        # Create combined visualization\n",
    "        combined_width = IMG_SIZE[0] * 3 + 120  # Increased spacing for larger images\n",
    "        combined_height = IMG_SIZE[1]\n",
    "\n",
    "        combined_img = Image.new(\"RGB\", (combined_width, combined_height + 50), \"white\")\n",
    "\n",
    "        # Convert images to PIL format\n",
    "        noisy_pil = Image.fromarray((noisy_img * 255).astype(np.uint8)).convert(\"RGB\")\n",
    "        predicted_pil = Image.fromarray((predicted_img * 255).astype(np.uint8)).convert(\"RGB\")\n",
    "        original_pil = Image.fromarray((original_img * 255).astype(np.uint8)).convert(\"RGB\")\n",
    "\n",
    "        # Paste images\n",
    "        combined_img.paste(noisy_pil, (0, 0))\n",
    "        combined_img.paste(predicted_pil, (IMG_SIZE[0] + 20, 0))\n",
    "        combined_img.paste(original_pil, (2 * (IMG_SIZE[0] + 20), 0))\n",
    "\n",
    "        # Add text\n",
    "        draw = ImageDraw.Draw(combined_img)\n",
    "        try:\n",
    "            font = ImageFont.truetype(FONT_PATH, FONT_SIZE)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        # Create metrics text\n",
    "        metrics_text = [\n",
    "            \"-\" * 50,\n",
    "            f\"PSNR: {metrics['psnr']:.2f} dB\",\n",
    "            f\"SSIM: {metrics['ssim']:.4f}\",\n",
    "            f\"Edge Preservation Ratio: {metrics['epr']:.4f}\",\n",
    "            f\"Noise Reduction Ratio: {metrics['noise_reduction_ratio']:.2f}x\",\n",
    "            f\"NPS Correlation: {metrics['nps_correlation']:.4f}\",\n",
    "            \"-\" * 50\n",
    "        ]\n",
    "        \n",
    "        # Calculate text height needed\n",
    "        line_height = FONT_SIZE + 2\n",
    "        text_height = len(metrics_text) * line_height\n",
    "        \n",
    "        # Adjust combined image height to accommodate metrics\n",
    "        new_combined_height = combined_height + text_height + 20\n",
    "        new_combined_img = Image.new(\"RGB\", (combined_width, new_combined_height), \"white\")\n",
    "        new_combined_img.paste(combined_img, (0, 0))\n",
    "        \n",
    "        # Add all metrics text\n",
    "        draw = ImageDraw.Draw(new_combined_img)\n",
    "        for i, line in enumerate(metrics_text):\n",
    "            y_position = combined_height + 10 + (i * line_height)\n",
    "            draw.text((10, y_position), line, fill=\"black\", font=font)\n",
    "\n",
    "        # Save combined image\n",
    "        combined_save_path = os.path.join(OUTPUT_DIR, f\"{os.path.splitext(image_file)[0]}_combined.png\")\n",
    "        new_combined_img.save(combined_save_path, quality=95, dpi=(300, 300))\n",
    "\n",
    "    print(f\"\\nProcessing completed. Combined images saved to {OUTPUT_DIR}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
